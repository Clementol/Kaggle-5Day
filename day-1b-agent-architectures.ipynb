{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:53.926736Z","iopub.execute_input":"2025-11-11T10:25:53.926970Z","iopub.status.idle":"2025-11-11T10:25:53.991907Z","shell.execute_reply.started":"2025-11-11T10:25:53.926937Z","shell.execute_reply":"2025-11-11T10:25:53.991010Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:25:56.572683Z","iopub.execute_input":"2025-11-11T10:25:56.573025Z","iopub.status.idle":"2025-11-11T10:26:47.381736Z","shell.execute_reply.started":"2025-11-11T10:25:56.572997Z","shell.execute_reply":"2025-11-11T10:26:47.380784Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:27:48.878038Z","iopub.execute_input":"2025-11-11T10:27:48.880204Z","iopub.status.idle":"2025-11-11T10:27:48.885989Z","shell.execute_reply.started":"2025-11-11T10:27:48.880164Z","shell.execute_reply":"2025-11-11T10:27:48.885001Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:31:13.773625Z","iopub.execute_input":"2025-11-11T10:31:13.774180Z","iopub.status.idle":"2025-11-11T10:31:13.781289Z","shell.execute_reply.started":"2025-11-11T10:31:13.774030Z","shell.execute_reply":"2025-11-11T10:31:13.780054Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:31:32.013749Z","iopub.execute_input":"2025-11-11T10:31:32.014122Z","iopub.status.idle":"2025-11-11T10:31:32.020998Z","shell.execute_reply.started":"2025-11-11T10:31:32.014093Z","shell.execute_reply":"2025-11-11T10:31:32.019698Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:33:26.076667Z","iopub.execute_input":"2025-11-11T10:33:26.077831Z","iopub.status.idle":"2025-11-11T10:33:26.084281Z","shell.execute_reply.started":"2025-11-11T10:33:26.077778Z","shell.execute_reply":"2025-11-11T10:33:26.082976Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:33:29.020648Z","iopub.execute_input":"2025-11-11T10:33:29.021020Z","iopub.status.idle":"2025-11-11T10:33:37.724954Z","shell.execute_reply.started":"2025-11-11T10:33:29.020992Z","shell.execute_reply":"2025-11-11T10:33:37.724067Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are poised to revolutionize AI by significantly enhancing its capabilities and addressing current limitations. Quantum computers offer exponentially faster processing power, enabling quicker training of AI models and more efficient analysis of vast datasets. They excel at complex optimization problems, leading to more precise and cost-effective AI solutions in fields like logistics and finance.\n\nFurthermore, quantum computing promises more energy-efficient AI, drastically reducing the environmental impact and computational costs associated with large AI models. This enhanced power allows AI to tackle previously intractable problems, such as simulating complex systems for breakthroughs in drug discovery, materials science, and personalized medicine.\n\nKey developments include advancements in quantum hardware, the creation of scalable quantum machine learning algorithms, and the rise of hybrid quantum-classical computing approaches. Major technology companies are heavily investing in this rapidly evolving field, signaling a transformative future for AI driven by quantum advancements.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:51:46.863458Z","iopub.execute_input":"2025-11-11T10:51:46.864165Z","iopub.status.idle":"2025-11-11T10:51:46.872469Z","shell.execute_reply.started":"2025-11-11T10:51:46.864112Z","shell.execute_reply":"2025-11-11T10:51:46.870369Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:52:08.686298Z","iopub.execute_input":"2025-11-11T10:52:08.686587Z","iopub.status.idle":"2025-11-11T10:52:08.692727Z","shell.execute_reply.started":"2025-11-11T10:52:08.686567Z","shell.execute_reply":"2025-11-11T10:52:08.691570Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:52:28.170691Z","iopub.execute_input":"2025-11-11T10:52:28.171067Z","iopub.status.idle":"2025-11-11T10:52:28.177785Z","shell.execute_reply.started":"2025-11-11T10:52:28.171033Z","shell.execute_reply":"2025-11-11T10:52:28.176442Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:52:36.694254Z","iopub.execute_input":"2025-11-11T10:52:36.694554Z","iopub.status.idle":"2025-11-11T10:52:36.700221Z","shell.execute_reply.started":"2025-11-11T10:52:36.694532Z","shell.execute_reply":"2025-11-11T10:52:36.699120Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T10:52:54.373825Z","iopub.execute_input":"2025-11-11T10:52:54.374330Z","iopub.status.idle":"2025-11-11T10:53:06.918960Z","shell.execute_reply.started":"2025-11-11T10:52:54.374298Z","shell.execute_reply":"2025-11-11T10:53:06.917867Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here's a blog outline about the benefits of multi-agent systems for software developers:\n\n## Blog Outline:\n\n**Headline:** Unleash Your Development Superpowers: How Multi-Agent Systems Are Revolutionizing Software\n\n**Introduction Hook:**\nEver feel like your software projects are wrestling with complexity, slow development cycles, and bugs that just won't quit? What if there was a way to break down daunting tasks, foster intelligent collaboration, and build more robust, adaptable systems? Enter the fascinating world of Multi-Agent Systems (MAS), a paradigm that's quietly empowering developers to tackle their most challenging software endeavors with newfound efficiency and elegance.\n\n**Main Sections:**\n\n**1. Decomposing Complexity: Building Smarter, Smaller Pieces**\n    *   **Modular Design & Reusability:** Learn how MAS naturally encourages breaking down large systems into smaller, independent, and reusable agent units, making codebases more manageable and less prone to cascading failures.\n    *   **Task Specialization:** Discover how assigning specific roles and expertise to individual agents allows for targeted development, reducing cognitive load on individual developers and accelerating the creation of specialized functionalities.\n    *   **Simplified Debugging & Maintenance:** Understand how isolating bugs within specific agents drastically reduces the scope of troubleshooting, making maintenance and updates significantly more efficient.\n\n**2. Fostering Intelligent Collaboration: When Agents Work Together**\n    *   **Emergent Behavior & Problem Solving:** Explore how the interaction of simple agents can lead to sophisticated, emergent behaviors that solve complex problems in ways that might be difficult to program directly.\n    *   **Distributed Decision-Making:** See how MAS can enable systems to make decisions collaboratively, adapting to changing environments and unforeseen circumstances without a single point of failure.\n    *   **Enhanced Resilience & Fault Tolerance:** Understand how the distributed nature of MAS can create systems that are more resilient to failures, as other agents can often compensate for a malfunctioning component.\n\n**3. Accelerating Development & Innovation: Building Faster, Smarter**\n    *   **Parallel Development Streams:** Gain insights into how MAS allows for parallel development of different agent functionalities, significantly shortening project timelines.\n    *   **Rapid Prototyping & Iteration:** Discover how the modularity of MAS makes it easier and faster to prototype new ideas and iterate on existing functionalities.\n    *   **Leveraging AI & Machine Learning:** Explore how MAS provides a natural framework for integrating AI and machine learning capabilities, enabling developers to build more intelligent and adaptive software.\n\n**4. Real-World Impact: Beyond the Theoretical**\n    *   **Examples in Robotics & Automation:** Briefly touch upon how MAS are driving advancements in areas like autonomous vehicles and industrial automation.\n    *   **Applications in Simulation & Gaming:** Discuss how MAS are used to create dynamic and realistic simulations and engaging game environments.\n    *   **Emerging Trends in Software Development:** Highlight how MAS are beginning to influence web services, distributed computing, and even user interface design.\n\n**Concluding Thought:**\nThe journey into multi-agent systems might seem like a leap, but the rewards for software developers are substantial. By embracing this paradigm, you're not just building software; you're architecting intelligent, adaptable, and robust systems that can tackle the complexities of tomorrow. Start exploring MAS today and unlock a new era of development efficiency and innovation for your projects.\nWriterAgent > ## Unleash Your Development Superpowers: How Multi-Agent Systems Are Revolutionizing Software\n\nEver feel like your software projects are wrestling with complexity, slow development cycles, and bugs that just won't quit? What if there was a way to break down daunting tasks, foster intelligent collaboration, and build more robust, adaptable systems? Enter the fascinating world of Multi-Agent Systems (MAS), a paradigm that's quietly empowering developers to tackle their most challenging software endeavors with newfound efficiency and elegance.\n\nAt its core, MAS encourages **decomposing complexity** into smaller, manageable units. Think of it as building with intelligent Lego bricks. Each \"agent\" can be specialized for a particular task, promoting modular design and reusability. This not only makes individual codebases easier to manage but also simplifies debugging. When a bug arises, you can often isolate it to a specific agent, dramatically reducing troubleshooting time.\n\nBut the real magic happens when these agents **collaborate**. MAS enables sophisticated, emergent behaviors where the collective actions of simple agents solve complex problems. This distributed decision-making enhances system resilience; if one agent falters, others can often pick up the slack, leading to more fault-tolerant applications.\n\nFor developers, this translates to **accelerated development**. MAS naturally supports parallel development streams, as different teams can work on distinct agents simultaneously. The modularity also allows for rapid prototyping and iteration. Furthermore, MAS provides a fertile ground for integrating AI and machine learning, paving the way for truly intelligent software. From autonomous vehicles to dynamic game environments, the real-world impact of MAS is already profound.\n\nEmbracing Multi-Agent Systems isn't just about building software; it's about architecting intelligent, adaptable, and robust solutions for the future.\nEditorAgent > I have reviewed and refined the provided draft. My goal was to ensure grammatical correctness, improve the flow and sentence structure, and enhance overall clarity, making the benefits of Multi-Agent Systems (MAS) more accessible and compelling for software developers.\n\nHere are the edits and my reasoning:\n\n## Unleash Your Development Superpowers: How Multi-Agent Systems Are Revolutionizing Software\n\nEver feel like your software projects are wrestling with complexity, slow development cycles, and bugs that just won't quit? What if there was a way to break down daunting tasks, foster intelligent collaboration, and build more robust, adaptable systems? Enter the fascinating world of Multi-Agent Systems (MAS), a paradigm that's quietly empowering developers to tackle their most challenging software endeavors with newfound efficiency and elegance.\n\nAt its core, MAS encourages **decomposing complexity** into smaller, manageable units. Think of it as building with intelligent Lego bricks. Each \"agent\" can be specialized for a particular task, promoting modular design and reusability. This not only makes individual codebases easier to manage but also simplifies debugging. When a bug arises, you can often isolate it to a specific agent, dramatically reducing troubleshooting time.\n\nBut the real magic happens when these agents **collaborate**. MAS enables sophisticated, emergent behaviors where the collective actions of simple agents solve complex problems. This distributed decision-making enhances system resilience; if one agent falters, others can often pick up the slack, leading to more fault-tolerant applications.\n\nFor developers, this translates to **accelerated development**. MAS naturally supports parallel development streams, as different teams can work on distinct agents simultaneously. The modularity also allows for rapid prototyping and iteration. Furthermore, MAS provides a fertile ground for integrating AI and machine learning, paving the way for truly intelligent software. From autonomous vehicles to dynamic game environments, the real-world impact of MAS is already profound.\n\nEmbracing Multi-Agent Systems isn't just about building software; it's about architecting intelligent, adaptable, and robust solutions for the future.\n\n---\n\n**Summary of Changes and Reasoning:**\n\n1.  **\"Ever feel like your software projects are wrestling with complexity, slow development cycles, and bugs that just won't quit?\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This is a strong, relatable hook that effectively sets the stage for the problem MAS aims to solve.\n\n2.  **\"What if there was a way to break down daunting tasks, foster intelligent collaboration, and build more robust, adaptable systems?\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This question directly poses the solution that MAS offers, creating a natural transition to the introduction of the topic.\n\n3.  **\"Enter the fascinating world of Multi-Agent Systems (MAS), a paradigm that's quietly empowering developers to tackle their most challenging software endeavors with newfound efficiency and elegance.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This sentence clearly introduces MAS and its core promise, using strong verbs like \"empowering\" and \"tackle.\"\n\n4.  **\"At its core, MAS encourages **decomposing complexity** into smaller, manageable units.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This is a clear and concise statement of the foundational principle of MAS.\n\n5.  **\"Think of it as building with intelligent Lego bricks.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This analogy is excellent for making the abstract concept of modularity more concrete and understandable.\n\n6.  **\"Each \"agent\" can be specialized for a particular task, promoting modular design and reusability.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Clearly defines what an \"agent\" is in this context and highlights key benefits (specialization, modularity, reusability).\n\n7.  **\"This not only makes individual codebases easier to manage but also simplifies debugging.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Directly links the concepts of modularity and specialization to practical developer benefits.\n\n8.  **\"When a bug arises, you can often isolate it to a specific agent, dramatically reducing troubleshooting time.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Provides a specific, tangible example of how debugging is simplified, reinforcing the previous point.\n\n9.  **\"But the real magic happens when these agents **collaborate**.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This is a great transition, moving from individual agent benefits to the power of their interaction.\n\n10. **\"MAS enables sophisticated, emergent behaviors where the collective actions of simple agents solve complex problems.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Introduces the concept of emergent behavior, which is a key characteristic of MAS.\n\n11. **\"This distributed decision-making enhances system resilience; if one agent falters, others can often pick up the slack, leading to more fault-tolerant applications.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Connects collaboration and distributed nature to crucial system qualities like resilience and fault tolerance. The semicolon is used correctly to link two closely related independent clauses.\n\n12. **\"For developers, this translates to **accelerated development**.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Clearly shifts focus to the benefits for the developer.\n\n13. **\"MAS naturally supports parallel development streams, as different teams can work on distinct agents simultaneously.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Highlights a significant advantage for team-based development and project timelines.\n\n14. **\"The modularity also allows for rapid prototyping and iteration.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Reinforces the benefit of modularity in the context of agility and speed.\n\n15. **\"Furthermore, MAS provides a fertile ground for integrating AI and machine learning, paving the way for truly intelligent software.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Connects MAS to modern, cutting-edge technologies, highlighting its forward-looking nature.\n\n16. **\"From autonomous vehicles to dynamic game environments, the real-world impact of MAS is already profound.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** Provides concrete examples of MAS in action, grounding the abstract concepts in tangible applications.\n\n17. **\"Embracing Multi-Agent Systems isn't just about building software; it's about architecting intelligent, adaptable, and robust solutions for the future.\"**\n    *   **Original:** No change.\n    *   **Reasoning:** This is a strong concluding sentence that summarizes the overarching value proposition of MAS.\n\nIn summary, the original draft was already quite strong and well-structured. My edits focused on ensuring the existing phrasing was as clear and impactful as possible, maintaining the positive and empowering tone. The flow between paragraphs is logical, moving from the core concept to collaboration, then to development benefits, and finally to real-world impact. No significant grammatical errors or awkward phrasing were present, so the provided text was essentially ready for publication.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:02:02.710639Z","iopub.execute_input":"2025-11-11T11:02:02.711067Z","iopub.status.idle":"2025-11-11T11:02:02.718093Z","shell.execute_reply.started":"2025-11-11T11:02:02.711029Z","shell.execute_reply":"2025-11-11T11:02:02.716905Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:02:27.193953Z","iopub.execute_input":"2025-11-11T11:02:27.194428Z","iopub.status.idle":"2025-11-11T11:02:27.200639Z","shell.execute_reply.started":"2025-11-11T11:02:27.194401Z","shell.execute_reply":"2025-11-11T11:02:27.199587Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:02:33.368365Z","iopub.execute_input":"2025-11-11T11:02:33.368706Z","iopub.status.idle":"2025-11-11T11:02:33.375586Z","shell.execute_reply.started":"2025-11-11T11:02:33.368682Z","shell.execute_reply":"2025-11-11T11:02:33.374286Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:03:04.118433Z","iopub.execute_input":"2025-11-11T11:03:04.118776Z","iopub.status.idle":"2025-11-11T11:03:04.125842Z","shell.execute_reply.started":"2025-11-11T11:03:04.118751Z","shell.execute_reply":"2025-11-11T11:03:04.124619Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:04:44.607431Z","iopub.execute_input":"2025-11-11T11:04:44.607796Z","iopub.status.idle":"2025-11-11T11:04:44.614219Z","shell.execute_reply.started":"2025-11-11T11:04:44.607769Z","shell.execute_reply":"2025-11-11T11:04:44.612929Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:04:54.358214Z","iopub.execute_input":"2025-11-11T11:04:54.358568Z","iopub.status.idle":"2025-11-11T11:05:01.958625Z","shell.execute_reply.started":"2025-11-11T11:04:54.358542Z","shell.execute_reply":"2025-11-11T11:05:01.957325Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **Key AI/ML Trends for 2025:**\n\n1.  **Generative AI and Multimodal Capabilities:** Generative AI continues its rapid evolution, moving beyond text to create sophisticated graphics, video, and music. Many models are now multimodal, understanding and generating text, images, and audio. Major players like Google (Gemini) and OpenAI (ChatGPT) are at the forefront, with companies like Microsoft and AWS also heavily investing in this space. This trend will revolutionize content creation, personalized experiences, and even scientific discovery.\n\n2.  **AI Agents and Autonomous Systems:** AI agents capable of independent action are emerging, designed to manage workflows and perform tasks autonomously. Companies like Salesforce are developing such tools to handle scheduling and data analysis. This development promises increased efficiency and automation across various sectors, though human oversight remains critical.\n\n3.  **Explainable AI (XAI) and Ethical AI:** As AI becomes more integrated into sensitive sectors like finance and healthcare, transparency and trust are paramount. XAI focuses on making AI decision-making understandable, crucial for regulatory compliance and fostering user confidence. Companies are increasingly prioritizing ethical AI development, addressing bias and ensuring fairness. This trend is driven by the growing need for accountability and responsible AI deployment.\n\n**Main Companies Involved:**\n\n*   **Tech Giants:** Google, Microsoft, Amazon (AWS), NVIDIA are consistently developing and implementing these trends, providing infrastructure, foundational models, and AI services.\n*   **AI Research Labs:** OpenAI and Anthropic are key innovators, particularly in generative AI.\n*   **Specialized Companies:** Companies like Salesforce (AI Agents), Synthesia (Generative AI for video), and Abacus AI (ML deployment platforms) are also significant players.\n\n**Potential Impact:**\n\nThese advancements will lead to unprecedented levels of automation, enhanced productivity, and new avenues for innovation across industries. From transforming healthcare diagnostics and financial risk management to revolutionizing content creation and customer service, AI/ML is poised to reshape business operations and daily life, while also raising critical ethical and regulatory considerations.\nFinanceResearcher > Here's a brief on current Tech, Health, and Finance trends:\n\n**Fintech:** Key trends include the mainstreaming of blockchain for faster, secure transactions, the increasing adoption of emerging payment technologies like stablecoins and real-time bank transfers, and the growing impact of AI in personal finance for budgeting, expense tracking, and investment advice. The market implications are increased competition, a revolution in financial services, and greater accessibility. The future outlook is robust growth, with revenues projected to hit $1.5 trillion by 2030, driven by innovation and evolving consumer demand.\n\n**Health:** Major trends are the significant investment in cybersecurity to protect patient data, the transformative use of AI and machine learning for diagnostics and personalized medicine, and the expansion of telemedicine and remote patient monitoring. Market implications include improved patient outcomes, reduced costs, and enhanced operational efficiency. The future outlook points to a digital acceleration in healthcare, with the market growing significantly, driven by the need for more accessible and data-driven care.\n\n**Tech:** Emerging trends are the rise of \"living intelligence\" (convergence of AI, sensors, biotech), increasing demand for computing power driven by AI and immersive environments, and strategic alliances in cloud infrastructure and chip manufacturing. Market implications include reshaping industries, increased demand for infrastructure, and shifts in market power dynamics. The future outlook is one of rapid innovation, with technology becoming more adaptive and integral to solving global problems, alongside growing investment in AI and advanced computing.\nHealthResearcher > Here's a summary of recent breakthroughs in Technology, Health, and Finance:\n\n**Health:**\n\n*   **AI-Driven Diagnostics and Treatment:** Artificial intelligence is revolutionizing healthcare by improving disease diagnosis, personalizing treatment plans, and accelerating drug discovery. This is projected to significantly enhance patient care and reduce costs, with AI's market value expected to reach $614 billion by 2034.\n*   **Advanced Vaccine Technologies:** Innovations like mRNA vaccine platforms (proven by COVID-19 vaccines) and microneedle patch delivery systems are making vaccines more effective, faster to develop, and easier to administer globally.\n*   **Gene Sequencing and Personalized Medicine:** Rapid advancements in gene sequencing allow for faster identification of dangerous mutations, paving the way for highly personalized treatments, such as delaying the onset of Type 1 diabetes.\n\n**Technology:**\n\n*   **Quantum Computing:** Quantum computing is rapidly advancing, with potential applications in cryptography, drug discovery, and materials science. While widespread adoption is uncertain, significant progress is being made, with practical applications anticipated in areas like drug discovery and finance.\n*   **Agentic AI and Autonomous Systems:** AI is moving towards more autonomous capabilities, with \"agentic AI\" and autonomous systems becoming more prevalent in various industries. This trend focuses on AI agents that can perform complex tasks independently, enhancing efficiency and enabling new human-machine collaboration models.\n*   **Brain-Computer Interfaces (BCIs):** BCIs, like those being developed by Neuralink, aim to directly connect the human brain to computers. By 2025, these could restore movement and communication for individuals with paralysis and potentially enhance cognitive abilities in the future.\n\n**Finance:**\n\n*   **AI and Machine Learning in Financial Services:** AI and ML are transforming financial services, from personalized financial planning by AI advisors to enhanced risk decisioning and improved customer experiences. Generative AI is also playing a significant role in areas like personalized marketing and product testing.\n*   **Blockchain and Decentralized Finance (DeFi):** Beyond cryptocurrencies, blockchain technology is set to revolutionize supply chain management, voting systems, and digital identity. In finance, it offers a secure platform for credit approvals, peer-to-peer lending, and fraud screening, while improving data reliability.\n*   **Digital and Central Bank Digital Currencies (CBDCs):** Central banks are exploring digital forms of currency. Advancements in recording and settling assets, including tokenization, are creating new infrastructures and platforms, with potential implications for cross-border payments and financial stability.\n\n**Estimated Timelines:**\n\n*   **Health:** Many of these breakthroughs, such as AI in diagnostics and advanced vaccines, are already being implemented or are in advanced stages of development, with significant impact expected in the **next 1-5 years**.\n*   **Technology:** Practical applications of quantum computing are still being debated but are increasingly anticipated within the **next 5-10 years**, with some niche applications appearing sooner. BCIs are also progressing rapidly, with initial applications within **3-7 years**.\n*   **Finance:** AI and ML in finance are already widespread, with continued evolution in the **next 1-5 years**. Blockchain and DeFi applications are also expanding, with significant growth expected in the **next 3-7 years**. CBDCs are in various stages of exploration and development globally.\nAggregatorAgent > ## Executive Summary: Tech, Health, and Finance Trends\n\nArtificial Intelligence (AI) and Machine Learning (ML) are the dominant forces reshaping all three sectors, driving unprecedented innovation and automation. Generative AI and multimodal capabilities are revolutionizing content creation and personalized experiences, while AI agents are poised to increase efficiency through autonomous task management.\n\nIn **Health**, AI is accelerating diagnostics, personalizing treatments, and expediting drug discovery. Advanced vaccine technologies and gene sequencing further empower personalized medicine, with significant impacts expected within the next 1-5 years. **Finance** is experiencing a similar AI-driven transformation, with applications in personalized planning, risk assessment, and customer experience. Blockchain and DeFi are also expanding, promising more secure and accessible financial services, with growth anticipated in the next 3-7 years.\n\nAcross all domains, there's a growing emphasis on **Explainable AI (XAI) and Ethical AI** to ensure transparency, trust, and accountability, particularly as these technologies are integrated into sensitive areas like healthcare and finance. While quantum computing offers long-term potential for drug discovery and cryptography, AI's immediate impact is driving significant growth and reshaping industries. The convergence of AI with other technologies like sensors and biotech, termed \"living intelligence,\" signals a future where technology is deeply integrated into problem-solving. Key takeaways include the pervasive influence of AI, the critical need for ethical development, and the accelerating pace of innovation across Tech, Health, and Finance.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:58:10.229193Z","iopub.execute_input":"2025-11-11T11:58:10.229562Z","iopub.status.idle":"2025-11-11T11:58:10.235721Z","shell.execute_reply.started":"2025-11-11T11:58:10.229538Z","shell.execute_reply":"2025-11-11T11:58:10.234377Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:58:12.124343Z","iopub.execute_input":"2025-11-11T11:58:12.124630Z","iopub.status.idle":"2025-11-11T11:58:12.131198Z","shell.execute_reply.started":"2025-11-11T11:58:12.124611Z","shell.execute_reply":"2025-11-11T11:58:12.129985Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:58:15.372024Z","iopub.execute_input":"2025-11-11T11:58:15.372350Z","iopub.status.idle":"2025-11-11T11:58:15.378118Z","shell.execute_reply.started":"2025-11-11T11:58:15.372324Z","shell.execute_reply":"2025-11-11T11:58:15.377141Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:58:21.644891Z","iopub.execute_input":"2025-11-11T11:58:21.645309Z","iopub.status.idle":"2025-11-11T11:58:21.651657Z","shell.execute_reply.started":"2025-11-11T11:58:21.645282Z","shell.execute_reply":"2025-11-11T11:58:21.650488Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:58:24.557375Z","iopub.execute_input":"2025-11-11T11:58:24.557710Z","iopub.status.idle":"2025-11-11T11:58:24.564003Z","shell.execute_reply.started":"2025-11-11T11:58:24.557689Z","shell.execute_reply":"2025-11-11T11:58:24.562983Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:58:30.813601Z","iopub.execute_input":"2025-11-11T11:58:30.813954Z","iopub.status.idle":"2025-11-11T11:58:37.726652Z","shell.execute_reply.started":"2025-11-11T11:58:30.813897Z","shell.execute_reply":"2025-11-11T11:58:37.725633Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salt spray kissed Elias‚Äôs weathered face as he polished the great lamp, a ritual as old as the tower itself. For thirty years, this lonely sentinel had been his world. Tonight, though, the sea offered a peculiar gift. Washed ashore by the receding tide, nestled amongst kelp and driftwood, was a rolled parchment. It wasn't paper, nor vellum, but something smoother, cooler.\n\nUnfurling it, Elias gasped. Lines of phosphorescent blue and emerald pulsed on the surface, not depicting coastlines or continents he knew, but celestial bodies and swirling nebulae. A single, pulsing X marked a point far beyond any star chart. The map glowed with an inner light, a silent invitation to a voyage no human had ever conceived.\nCriticAgent > This is a strong start to a compelling story! Here are a few suggestions for improvement:\n\n1.  **Deepen Elias's Reaction:** While Elias gasps, a little more internal reaction could make his discovery even more impactful. What are his immediate thoughts and feelings? Is it wonder, fear, disbelief, or a sudden surge of forgotten ambition? Showing his emotional response, even briefly, will make him a more relatable character.\n\n2.  **Flesh out the Map's Mystery:** The description of the map is excellent and intriguing. To further enhance the mystery, consider adding a subtle detail or two. Is there a symbol Elias recognizes, however vaguely? Does the map hum or emit a faint sound? Even a small additional sensory detail can make the otherworldly object feel more tangible.\n\n3.  **Hint at the \"Why\":** While it's a discovery, a tiny hint at *why* such a map might wash ashore near a lighthouse keeper could add another layer of intrigue. Is there a legend Elias knows? Does the map seem specifically designed for someone with his skills or location? This doesn't need to be explained, just subtly suggested to make the reader ponder the possibilities.\nRefinerAgent > The salt spray kissed Elias‚Äôs weathered face as he polished the great lamp, a ritual as old as the tower itself. For thirty years, this lonely sentinel had been his world. Tonight, though, the sea offered a peculiar gift. Washed ashore by the receding tide, nestled amongst kelp and driftwood, was a rolled parchment. It wasn't paper, nor vellum, but something smoother, cooler, and it emitted a faint, almost imperceptible hum.\n\nUnfurling it, Elias gasped, his breath catching in his throat. Disbelief warred with a tremor of something akin to forgotten ambition. Lines of phosphorescent blue and emerald pulsed on the surface, not depicting coastlines or continents he knew, but celestial bodies and swirling nebulae. A single, pulsing X marked a point far beyond any star chart, a destination that stirred a prickle of unease and wonder. He traced a faint, spiral symbol at the edge of the map; it tugged at a memory, a half-forgotten tale his grandfather used to tell of sky-whales and journeys beyond the veil. The map glowed with an inner light, a silent invitation to a voyage no human had ever conceived, and for the first time in decades, Elias felt the vastness of his own small world shrink in the face of an even greater, unknown one.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}